---
layout: default
---

  <div id="page">
    <header class="page-header">
      <h2>Publications</h2>
    </header>
    <article class="page-content">
      <font size=3>
    <h3><font color=black>Inertial Bregman Proximal Gradient Algorithms in Non-Convex Optimization</font></h3>
    <ul>
      <li><b><font color=red>[NEW]</font></b> <a href="/publications_pdfs/Beyond-Alternating-Updates-for-Matrix-Factorization-with Inertial-Bregman-Proximal-Gradient-Algorithms.pdf" target="_blank"><b>Beyond Alternating Updates for Matrix Factorization with Inertial Bregman Proximal Gradient Algorithms</b></a> joint work with Peter Ochs.</li> 
      <b>
            <a target="_blank" href="https://arxiv.org/abs/1905.09050"> [arXiv] </a>
            <a target="_blank" href="/publications_pdfs/Beyond-Alternating-Updates-for-Matrix-Factorization-with Inertial-Bregman-Proximal-Gradient-Algorithms.pdf"> [Download PDF] </a>
            <a target="_blank" href="http://www.optimization-online.org/DB_HTML/2019/05/7224.html"> [Optimization Online] </a>
            <a target="_blank" href="https://github.com/mmahesh/cocain-bpg-matrix-factorization"> [Code] </a>
            <a target="_blank" href="/articles/2019-05/Beyond-Alternating-Updates-for-Matrix-Factorization-with-Inertial-Bregman-Proximal-Gradient-Algorithms"> [Blog Post] </a><a target="_blank" href="https://www.researchgate.net/publication/333309226_Beyond_Alternating_Updates_for_Matrix_Factorization_with_Inertial_Bregman_Proximal_Gradient_Algorithms"> [ResearchGate] </a>
          </b>
      <br>
      <br>
      <li><b><font color=red>[NEW]</font></b> <a href="/publications_pdfs/Convex-Concave-Backtracking-for-Inertial-Bregman-Proximal-Gradient-Algorithms-in-Non-Convex-Optimization.pdf" target="_blank"><b>Convex-Concave Backtracking for Inertial Bregman Proximal Gradient Algorithms in Non-Convex Optimization</b></a> joint work with Peter Ochs, Thomas Pock and Shoham Sabach.</li>
      <b>
            <a target="_blank" href="https://arxiv.org/abs/1904.03537"> [arXiv] </a>
            <a target="_blank" href="/publications_pdfs/Convex-Concave-Backtracking-for-Inertial-Bregman-Proximal-Gradient-Algorithms-in-Non-Convex-Optimization.pdf"> [Download PDF] </a>
            <a target="_blank" href="http://www.optimization-online.org/DB_HTML/2019/04/7159.html"> [Optimization Online] </a>
            <a target="_blank" href="/articles/2019-04/Convex-Concave-Backtracking-for-Inertial-Bregman-Proximal-Gradient-Algorithms-in-Non-Convex-Optimization"> [Blog Post] </a><a target="_blank" href="https://www.researchgate.net/publication/332300750_Convex-Concave_Backtracking_for_Inertial_Bregman_Proximal_Gradient_Algorithms_in_Non-Convex_Optimization"> [ResearchGate] </a>
          </b>
    </ul>
    <h3><font color=black> Deep Learning Theory</font></h3>
    <ul>
      <li> <a href="/publications_pdfs/On_the_Loss_Landscape_of_a_class_of_Deep_neural_networks_with_no_bad_local_valleys_Quynh_Nguyen_Mahesh_Chandra_Mukkamala_Matthias_Hein.pdf" target="_blank"><b>On the Loss Landscape of a class of Deep neural networks with no bad local valleys</b></a>  joint work with Quynh Nguyen and Matthias Hein is accepted at International Conference on Learning Representations (ICLR) 2019. 
        </li> 
        <b>
            <a target="_blank" href="https://arxiv.org/abs/1809.10749"> [arxiv] </a>
            <a target="_blank" href="/publications_pdfs/On_the_Loss_Landscape_of_a_class_of_Deep_neural_networks_with_no_bad_local_valleys_Quynh_Nguyen_Mahesh_Chandra_Mukkamala_Matthias_Hein.pdf"> [Download PDF] </a>
            <a target="_blank" href="https://www.researchgate.net/publication/327945221_On_the_Loss_Landscape_of_a_Class_of_Deep_Neural_Networks_with_No_Bad_Local_Valleys"> [ResearchGate] </a>
          </b>
        <br>
        <br>
      <li> <a href="/publications_pdfs/Neural_Networks_Should_Be_Wide_Enough_to_Learn_Disconnected_Decision_Regions_Quynh_Nguyen_Mahesh_Chandra_Mukkamala_Matthias_Hein.pdf" target="_blank"><b>Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions</b></a>  joint work with Quynh Nguyen and Matthias Hein is accepted at International Conference on Machine Learning (ICML) 2018. 
        </li>
        <b>
            <a target="_blank" href="https://arxiv.org/abs/1803.00094"> [arxiv] </a>
            <a target="_blank" href="/publications_pdfs/Neural_Networks_Should_Be_Wide_Enough_to_Learn_Disconnected_Decision_Regions_Quynh_Nguyen_Mahesh_Chandra_Mukkamala_Matthias_Hein.pdf"> [Download PDF] </a>
            <a target="_blank" href="https://www.researchgate.net/publication/323509979_Neural_Networks_Should_Be_Wide_Enough_to_Learn_Disconnected_Decision_Regions"> [ResearchGate] </a>
          </b>
      
    </ul>
    <h3><font color=black>Stochastic/Online Optimization for Deep Learning</font></h3>
    <ul>
      <li> <a href="/publications_pdfs/Variants_of_RMSProp_and_Adagrad_with_Logarithmic_Regret_Bounds_Mahesh_Chandra_Mukkamala_Matthias_Hein_ICML17.pdf" target="_blank"><b>Variants of RMSProp and Adagrad with Logarithmic Regret Bounds</b></a>  joint work with Matthias Hein is accepted at International Conference on Machine Learning (ICML) 2017.
      <br>
       <b>
            <a target="_blank" href="https://github.com/mmahesh/variants_of_rmsprop_and_adagrad"> [Code] </a> <a target="_blank" href="/main.pdf"> [Poster] </a><a target="_blank" href="/icml_slides.pdf">[ICML slides]</a><a target="_blank" href="https://arxiv.org/abs/1706.05507"> [arxiv] </a><a target="_blank" href="/publications_pdfs/Variants_of_RMSProp_and_Adagrad_with_Logarithmic_Regret_Bounds_Mahesh_Chandra_Mukkamala_Matthias_Hein_ICML17.pdf"> [Download PDF] </a><a target="_blank" href="/articles/2017-06/variants-of-rmsprop-and-adagrad-with-logarithmic-regret-bounds"> [Blog Post] </a><a target="_blank" href="/articles/2017-07/tutorial-on-sc-adagrad-a-new-stochastic-gradient-method-for-deep-learning"> [Tutorial] </a><a target="_blank" href="https://www.researchgate.net/publication/317679430_Variants_of_RMSProp_and_Adagrad_with_Logarithmic_Regret_Bounds"> [ResearchGate] </a>
            
          </b>
      <br><br>
      Also see long version containing all proofs <a href="http://www.ml.uni-saarland.de/Publications/MukHei-VariantsRMSPropAdagradLogRegretLongVersion.pdf" target="_blank"> here</a> 
    </li>
    </ul>

  </font>
    </article>


  </div><!-- end page content -->

